{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded from https://grouplens.org/datasets/movielens/25m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP8j_WzyfHD0",
    "outputId": "0164cd13-cdaa-4a05-99ff-ea2929ea6348"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "dbg = True\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "nrows = {True:100000, False:None}[dbg]\n",
    "rating_df = pd.read_csv('ml-25m/ratings.csv', nrows=nrows)\n",
    "tag_df = pd.read_csv('ml-25m/tags.csv', nrows=nrows)\n",
    "movie_df = pd.read_csv('ml-25m/movies.csv')\n",
    "rating_df['userId'] = rating_df['userId'] - 1\n",
    "rating_df['movieId'] = rating_df['movieId'] - 1\n",
    "tag_df['userId'] = tag_df['userId'] - 1\n",
    "tag_df['movieId'] = tag_df['movieId'] - 1\n",
    "movie_df['movieId'] = movie_df['movieId'] - 1\n",
    "\n",
    "rating_df['movieId'] = rating_df['movieId'].map({v: i for i, v in enumerate(rating_df['movieId'].unique())})\n",
    "mismatch = set(rating_df[\"movieId\"]).difference(movie_df[\"movieId\"])\n",
    "rating_df = rating_df.loc[~rating_df['movieId'].isin(mismatch)]\n",
    "\n",
    "movie_counts = rating_df['movieId'].value_counts()\n",
    "popular_movies = movie_counts[(movie_counts > 30)].index\n",
    "rating_df = rating_df.loc[rating_df['movieId'].isin(popular_movies)]\n",
    "user_counts = rating_df['userId'].value_counts()\n",
    "popular_users = user_counts[(user_counts > 30)].index\n",
    "rating_df = rating_df.loc[rating_df['userId'].isin(popular_users)]\n",
    "\n",
    "movie_df = movie_df.loc[movie_df['movieId'].isin(rating_df['movieId'].unique())]\n",
    "movie_id_map = {v:k for k, v in enumerate(rating_df['movieId'].unique())}\n",
    "movie_df['movieId'] = movie_df['movieId'].map(movie_id_map).astype(int)\n",
    "rating_df['movieId'] = rating_df['movieId'].map(movie_id_map).astype(int)\n",
    "user_id_map = {v:k for k, v in enumerate(rating_df['userId'].unique())}\n",
    "rating_df['userId'] = rating_df['userId'].map(user_id_map).astype(int)\n",
    "rating_df = rating_df.reset_index(drop=True)\n",
    "movie_df = movie_df.reset_index(drop=True)\n",
    "mismatch = set(movie_df[\"movieId\"]).difference(rating_df[\"movieId\"])\n",
    "movie_df = movie_df.drop(mismatch)\n",
    "num_users = rating_df['userId'].nunique()\n",
    "num_movies = rating_df['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows=np.random.choice(rating_df.shape[0], int(0.8*rating_df.shape[0]), replace=False)\n",
    "ratings_train = rating_df.loc[train_rows]\n",
    "test_rows = set(range(rating_df.shape[0])).difference(set(train_rows))\n",
    "ratings_test = rating_df.loc[test_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minrating, maxrating = rating_df['rating'].describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF:\n",
    "    def __init__(self, num_users, num_movies, minrating, max_rating, emb_size=8):\n",
    "        self.user_vec = tfvar(\"uservec\", shape=(num_users, emb_size), dtype=tf.float32)\n",
    "        self.movie_vec = tfvar(\"movievec\", shape=(num_movies, emb_size), dtype=tf.float32)\n",
    "        self.user_bias_vec = tfvar(\"userbiasvec\", shape=(num_users), dtype=tf.float32)\n",
    "        self.movie_bias_vec = tfvar(\"moviebiasvec\", shape=(num_movies), dtype=tf.float32)\n",
    "\n",
    "        self.user_ph = tfph(tf.int32, shape=(None))\n",
    "        self.movie_ph = tfph(tf.int32, shape=(None))\n",
    "        self.rating_ph = tfph(tf.float32, shape=(None))\n",
    "\n",
    "        # batch size, emb_size\n",
    "        self.user_emb = tf.gather(self.user_vec, self.user_ph)\n",
    "        self.movie_emb = tf.gather(self.movie_vec, self.movie_ph)\n",
    "\n",
    "        # batch size\n",
    "        self.user_bias_emb = tf.gather(self.user_bias_vec, self.user_ph)\n",
    "        self.movie_bias_emb = tf.gather(self.movie_bias_vec, self.movie_ph)\n",
    "\n",
    "        self.score_raw = (\n",
    "            tf.reduce_sum(self.user_emb * self.movie_emb, axis=1) + self.user_bias_emb + self.movie_bias_emb\n",
    "        )\n",
    "        self.score = self.score_raw * (maxrating - minrating) + minrating\n",
    "\n",
    "        self.reg = tf.reduce_mean(tf.square(self.user_emb)) + tf.reduce_mean(tf.square(self.movie_emb))\n",
    "\n",
    "        self.mse = tf.reduce_mean(tf.square(self.score - self.rating_ph))\n",
    "        self.loss = self.mse + self.reg\n",
    "        self.opt_fcn = tf.compat.v1.train.AdamOptimizer()\n",
    "        self.opt = self.opt_fcn.minimize(self.loss)\n",
    "        self.sess = tf.compat.v1.Session()\n",
    "        self.sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        self.saver = tf.compat.v1.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfph = tf.compat.v1.placeholder\n",
    "tfvar = tf.compat.v1.get_variable\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "mf_mdl = MF(num_users, num_movies, minrating, maxrating, emb_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "losses = []\n",
    "chk_freq = 10\n",
    "val_losses = []\n",
    "early_stopping = False\n",
    "batch_size = 64\n",
    "minibatch = 1\n",
    "n_trn = ratings_train.shape[0]\n",
    "for ep in range(epochs):\n",
    "    if minibatch:\n",
    "        data_order = np.arange(n_trn)\n",
    "        np.random.shuffle(data_order)\n",
    "        num_batches = n_trn // batch_size\n",
    "        loss_avg = 0\n",
    "        for batch_idx in range(num_batches):\n",
    "            if batch_idx != num_batches - 1:\n",
    "                rows = data_order[batch_idx*batch_size: (batch_idx+1) * batch_size]\n",
    "            else:\n",
    "                rows = data_order[batch_idx*batch_size:]\n",
    "            samples = ratings_train.iloc[rows]\n",
    "            \n",
    "            current_loss, _ = sess.run([loss, opt], {movie_ph: samples['movieId'], \n",
    "                                             user_ph: samples['userId'], \n",
    "                                             rating_ph: samples['rating']})\n",
    "            loss_avg += current_loss * len(rows) / n_trn\n",
    "        losses.append(loss_avg)\n",
    "        \n",
    "    else:\n",
    "        current_loss, _ = sess.run([loss, opt], {movie_ph: ratings_train['movieId'], \n",
    "                                             user_ph: ratings_train['userId'], \n",
    "                                             rating_ph: ratings_train['rating']})\n",
    "        losses.append(current_loss)\n",
    "    \n",
    "    if early_stopping:\n",
    "        if ep % chk_freq == 0:\n",
    "            last_chkpnt = f'rec_tst_{ep}'\n",
    "            saver.save(sess, last_chkpnt)\n",
    "    \n",
    "    val_loss = sess.run(loss, {\n",
    "        movie_ph: ratings_test['movieId'], \n",
    "        user_ph: ratings_test['userId'], \n",
    "        rating_ph: ratings_test['rating']})\n",
    "    \n",
    "    val_losses.append(val_loss)\n",
    "    if early_stopping:\n",
    "        if all([los > val_losses[ep - (ep % 10)] for los in val_losses[-3:]]):\n",
    "            saver.restore(sess, last_chkpnt)\n",
    "            restored_loss = sess.run(loss, {\n",
    "                        movie_ph: ratings_test['movieId'], \n",
    "                        user_ph: ratings_test['userId'], \n",
    "                        rating_ph: ratings_test['rating']})\n",
    "            val_losses.append(restored_loss)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses, label='train')\n",
    "plt.plot(val_losses, label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(user_emb, {movie_ph: ratings_train['movieId'], \n",
    "                                             user_ph: ratings_train['userId'], \n",
    "                                             rating_ph: ratings_train['rating']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Joel_2022_7_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
