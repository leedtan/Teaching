{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded from https://grouplens.org/datasets/movielens/25m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP8j_WzyfHD0",
    "outputId": "0164cd13-cdaa-4a05-99ff-ea2929ea6348"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "dbg = True\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "nrows = {True:100000, False:None}[dbg]\n",
    "rating_df = pd.read_csv('ml-25m/ratings.csv', nrows=nrows)\n",
    "tag_df = pd.read_csv('ml-25m/tags.csv', nrows=nrows)\n",
    "movie_df = pd.read_csv('ml-25m/movies.csv')\n",
    "rating_df['userId'] = rating_df['userId'] - 1\n",
    "rating_df['movieId'] = rating_df['movieId'] - 1\n",
    "tag_df['userId'] = tag_df['userId'] - 1\n",
    "tag_df['movieId'] = tag_df['movieId'] - 1\n",
    "movie_df['movieId'] = movie_df['movieId'] - 1\n",
    "\n",
    "rating_df['movieId'] = rating_df['movieId'].map({v: i for i, v in enumerate(rating_df['movieId'].unique())})\n",
    "mismatch = set(rating_df[\"movieId\"]).difference(movie_df[\"movieId\"])\n",
    "rating_df = rating_df.loc[~rating_df['movieId'].isin(mismatch)]\n",
    "\n",
    "movie_counts = rating_df['movieId'].value_counts()\n",
    "popular_movies = movie_counts[(movie_counts > 30)].index\n",
    "rating_df = rating_df.loc[rating_df['movieId'].isin(popular_movies)]\n",
    "user_counts = rating_df['userId'].value_counts()\n",
    "popular_users = user_counts[(user_counts > 30)].index\n",
    "rating_df = rating_df.loc[rating_df['userId'].isin(popular_users)]\n",
    "\n",
    "movie_df = movie_df.loc[movie_df['movieId'].isin(rating_df['movieId'].unique())]\n",
    "movie_id_map = {v:k for k, v in enumerate(rating_df['movieId'].unique())}\n",
    "movie_df['movieId'] = movie_df['movieId'].map(movie_id_map).astype(int)\n",
    "rating_df['movieId'] = rating_df['movieId'].map(movie_id_map).astype(int)\n",
    "user_id_map = {v:k for k, v in enumerate(rating_df['userId'].unique())}\n",
    "rating_df['userId'] = rating_df['userId'].map(user_id_map).astype(int)\n",
    "rating_df = rating_df.reset_index(drop=True)\n",
    "movie_df = movie_df.reset_index(drop=True)\n",
    "mismatch = set(movie_df[\"movieId\"]).difference(rating_df[\"movieId\"])\n",
    "movie_df = movie_df.drop(mismatch)\n",
    "num_users = rating_df['userId'].nunique()\n",
    "num_movies = rating_df['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows=np.random.choice(rating_df.shape[0], int(0.8*rating_df.shape[0]), replace=False)\n",
    "ratings_train = rating_df.loc[train_rows]\n",
    "test_rows = set(range(rating_df.shape[0])).difference(set(train_rows))\n",
    "ratings_test = rating_df.loc[test_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "minrating, maxrating = rating_df['rating'].describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecEngine:\n",
    "    def __init__(self, ratings_train, ratings_test, num_users, num_movies, minrating, maxrating, emb_size=8,\n",
    "                 early_stopping = False, chk_freq = 10, *args, **kwargs):\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        self.user_vec = tfvar(\"uservec\", shape=(num_users, emb_size), dtype=tf.float32)\n",
    "        self.movie_vec = tfvar(\"movievec\", shape=(num_movies, emb_size), dtype=tf.float32)\n",
    "        self.user_bias_vec = tfvar(\"userbiasvec\", shape=(num_users), dtype=tf.float32)\n",
    "        self.movie_bias_vec = tfvar(\"moviebiasvec\", shape=(num_movies), dtype=tf.float32)\n",
    "        self.ratings_train = ratings_train\n",
    "        self.ratings_test = ratings_test\n",
    "\n",
    "        self.user_ph = tfph(tf.int32, shape=(None))\n",
    "        self.movie_ph = tfph(tf.int32, shape=(None))\n",
    "        self.rating_ph = tfph(tf.float32, shape=(None))\n",
    "        \n",
    "        self.losses = []\n",
    "        self.chk_freq = chk_freq\n",
    "        self.val_losses = []\n",
    "        self.early_stopping = early_stopping\n",
    "        if early_stopping and chk_frq == 0:\n",
    "            raise ValueError('need a check freq if using early stopping')\n",
    "        self.n_trn = ratings_train.shape[0]\n",
    "        \n",
    "    def sample_at(self, rows):\n",
    "\n",
    "        samples = self.ratings_train.iloc[rows]\n",
    "        fd = {self.movie_ph: samples['movieId'], self.user_ph: samples['userId'], self.rating_ph: samples['rating']}\n",
    "        return fd\n",
    "    def get_fd_train(self):\n",
    "        fd = {self.movie_ph: self.ratings_train['movieId'], \n",
    "             self.user_ph: self.ratings_train['userId'], \n",
    "             self.rating_ph: self.ratings_train['rating']}\n",
    "        return fd\n",
    "    def get_fd_test(self):\n",
    "        fd =  {self.movie_ph: self.ratings_test['movieId'], \n",
    "                self.user_ph: self.ratings_test['userId'], \n",
    "                self.rating_ph: self.ratings_test['rating']}\n",
    "        return fd\n",
    "    def train(self, epochs = 100, minibatch = True, batch_size = 64):\n",
    "        for ep in range(epochs):\n",
    "            if minibatch:\n",
    "                data_order = np.arange(self.n_trn)\n",
    "                np.random.shuffle(data_order)\n",
    "                num_batches = n_trn // batch_size\n",
    "                loss_avg = 0\n",
    "                for batch_idx in range(num_batches):\n",
    "                    if batch_idx != num_batches - 1:\n",
    "                        rows = data_order[batch_idx*batch_size: (batch_idx+1) * batch_size]\n",
    "                    else:\n",
    "                        rows = data_order[batch_idx*batch_size:]\n",
    "                    fd = self.sample_at(rows)\n",
    "                    current_loss, _ = self.sess.run([self.loss, self.opt], fd)\n",
    "                    loss_avg += current_loss * len(rows) / n_trn\n",
    "                self.losses.append(loss_avg)\n",
    "\n",
    "            else:\n",
    "                fd = self.get_fd_train()\n",
    "                current_loss, _ = self.sess.run([self.loss, self.opt], fd)\n",
    "                self.losses.append(current_loss)\n",
    "\n",
    "            if early_stopping:\n",
    "                if ep % chk_freq == 0:\n",
    "                    last_chkpnt = f'rec_tst_{ep}'\n",
    "                    self.saver.save(self.sess, last_chkpnt)\n",
    "            fd_test = self.get_fd_test()\n",
    "            val_loss = self.sess.run(self.loss,fd_test)\n",
    "\n",
    "            self.val_losses.append(val_loss)\n",
    "            if early_stopping:\n",
    "                if all([los > val_losses[ep - (ep % 10)] for los in self.val_losses[-3:]]):\n",
    "                    self.saver.restore(self.sess, last_chkpnt)\n",
    "                    fd = self.get_fd_test()\n",
    "                    restored_loss = self.sess.run(self.loss, fd)\n",
    "                    self.val_losses.append(restored_loss)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(RecEngine):\n",
    "    def __init__(self, minrating, maxrating, *args, **kwargs):\n",
    "        super().__init__(minrating=minrating, maxrating=maxrating, *args, **kwargs)\n",
    "#         tf.compat.v1.reset_default_graph()\n",
    "#         self.user_vec = tfvar(\"uservec\", shape=(num_users, emb_size), dtype=tf.float32)\n",
    "#         self.movie_vec = tfvar(\"movievec\", shape=(num_movies, emb_size), dtype=tf.float32)\n",
    "#         self.user_bias_vec = tfvar(\"userbiasvec\", shape=(num_users), dtype=tf.float32)\n",
    "#         self.movie_bias_vec = tfvar(\"moviebiasvec\", shape=(num_movies), dtype=tf.float32)\n",
    "#         self.ratings_train = ratings_train\n",
    "\n",
    "#         self.user_ph = tfph(tf.int32, shape=(None))\n",
    "#         self.movie_ph = tfph(tf.int32, shape=(None))\n",
    "#         self.rating_ph = tfph(tf.float32, shape=(None))\n",
    "\n",
    "        # batch size, emb_size\n",
    "        self.user_emb = tf.gather(self.user_vec, self.user_ph)\n",
    "        self.movie_emb = tf.gather(self.movie_vec, self.movie_ph)\n",
    "\n",
    "        # batch size\n",
    "        self.user_bias_emb = tf.gather(self.user_bias_vec, self.user_ph)\n",
    "        self.movie_bias_emb = tf.gather(self.movie_bias_vec, self.movie_ph)\n",
    "\n",
    "        self.score_raw = (\n",
    "            tf.reduce_sum(self.user_emb * self.movie_emb, axis=1) + self.user_bias_emb + self.movie_bias_emb\n",
    "        )\n",
    "        self.score = self.score_raw * (maxrating - minrating) + minrating\n",
    "\n",
    "        self.reg = tf.reduce_mean(tf.square(self.user_emb)) + tf.reduce_mean(tf.square(self.movie_emb))\n",
    "\n",
    "        self.mse = tf.reduce_mean(tf.square(self.score - self.rating_ph))\n",
    "        self.loss = self.mse + self.reg\n",
    "        self.opt_fcn = tf.compat.v1.train.AdamOptimizer()\n",
    "        self.opt = self.opt_fcn.minimize(self.loss)\n",
    "        self.sess = tf.compat.v1.Session()\n",
    "        self.sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        self.saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfph = tf.compat.v1.placeholder\n",
    "tfvar = tf.compat.v1.get_variable\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "mf_mdl = MF(ratings_train=ratings_train, num_users=num_users, num_movies=num_movies,\n",
    "            minrating=minrating, maxrating=maxrating, emb_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MF' object has no attribute 'ratings_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-1ac35693af25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmf_mdl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-efcbaf990d29>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, minibatch, batch_size)\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mlast_chkpnt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'rec_tst_{ep}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_chkpnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[0mfd_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_fd_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfd_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-efcbaf990d29>\u001b[0m in \u001b[0;36mget_fd_test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_fd_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         fd =  {self.movie_ph: self.ratings_test['movieId'], \n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 self.rating_ph: self.ratings_test['rating']}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MF' object has no attribute 'ratings_test'"
     ]
    }
   ],
   "source": [
    "mf_mdl.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-b308d58a1901>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mratings_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrows\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             current_loss, _ = sess.run([loss, opt], {movie_ph: samples['movieId'], \n\u001b[0m\u001b[0;32m     23\u001b[0m                                              \u001b[0muser_ph\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'userId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                                              rating_ph: samples['rating']})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "losses = []\n",
    "chk_freq = 10\n",
    "val_losses = []\n",
    "early_stopping = False\n",
    "batch_size = 64\n",
    "minibatch = 1\n",
    "n_trn = ratings_train.shape[0]\n",
    "for ep in range(epochs):\n",
    "    if minibatch:\n",
    "        data_order = np.arange(n_trn)\n",
    "        np.random.shuffle(data_order)\n",
    "        num_batches = n_trn // batch_size\n",
    "        loss_avg = 0\n",
    "        for batch_idx in range(num_batches):\n",
    "            if batch_idx != num_batches - 1:\n",
    "                rows = data_order[batch_idx*batch_size: (batch_idx+1) * batch_size]\n",
    "            else:\n",
    "                rows = data_order[batch_idx*batch_size:]\n",
    "            samples = ratings_train.iloc[rows]\n",
    "            \n",
    "            current_loss, _ = sess.run([loss, opt], {movie_ph: samples['movieId'], \n",
    "                                             user_ph: samples['userId'], \n",
    "                                             rating_ph: samples['rating']})\n",
    "            loss_avg += current_loss * len(rows) / n_trn\n",
    "        losses.append(loss_avg)\n",
    "        \n",
    "    else:\n",
    "        current_loss, _ = sess.run([loss, opt], {movie_ph: ratings_train['movieId'], \n",
    "                                             user_ph: ratings_train['userId'], \n",
    "                                             rating_ph: ratings_train['rating']})\n",
    "        losses.append(current_loss)\n",
    "    \n",
    "    if early_stopping:\n",
    "        if ep % chk_freq == 0:\n",
    "            last_chkpnt = f'rec_tst_{ep}'\n",
    "            saver.save(sess, last_chkpnt)\n",
    "    \n",
    "    val_loss = sess.run(loss, {\n",
    "        movie_ph: ratings_test['movieId'], \n",
    "        user_ph: ratings_test['userId'], \n",
    "        rating_ph: ratings_test['rating']})\n",
    "    \n",
    "    val_losses.append(val_loss)\n",
    "    if early_stopping:\n",
    "        if all([los > val_losses[ep - (ep % 10)] for los in val_losses[-3:]]):\n",
    "            saver.restore(sess, last_chkpnt)\n",
    "            restored_loss = sess.run(loss, {\n",
    "                        movie_ph: ratings_test['movieId'], \n",
    "                        user_ph: ratings_test['userId'], \n",
    "                        rating_ph: ratings_test['rating']})\n",
    "            val_losses.append(restored_loss)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses, label='train')\n",
    "plt.plot(val_losses, label='validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(user_emb, {movie_ph: ratings_train['movieId'], \n",
    "                                             user_ph: ratings_train['userId'], \n",
    "                                             rating_ph: ratings_train['rating']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Joel_2022_7_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
