{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded from https://grouplens.org/datasets/movielens/25m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LP8j_WzyfHD0",
    "outputId": "0164cd13-cdaa-4a05-99ff-ea2929ea6348"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "dbg = True\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "nrows = {True:100000, False:None}[dbg]\n",
    "rating_df = pd.read_csv('ml-25m/ratings.csv', nrows=nrows)\n",
    "tag_df = pd.read_csv('ml-25m/tags.csv', nrows=nrows)\n",
    "movie_df = pd.read_csv('ml-25m/movies.csv')\n",
    "rating_df['userId'] = rating_df['userId'] - 1\n",
    "rating_df['movieId'] = rating_df['movieId'] - 1\n",
    "tag_df['userId'] = tag_df['userId'] - 1\n",
    "tag_df['movieId'] = tag_df['movieId'] - 1\n",
    "movie_df['movieId'] = movie_df['movieId'] - 1\n",
    "\n",
    "rating_df['movieId'] = rating_df['movieId'].map({v: i for i, v in enumerate(rating_df['movieId'].unique())})\n",
    "mismatch = set(rating_df[\"movieId\"]).difference(movie_df[\"movieId\"])\n",
    "rating_df = rating_df.loc[~rating_df['movieId'].isin(mismatch)]\n",
    "\n",
    "movie_counts = rating_df['movieId'].value_counts()\n",
    "popular_movies = movie_counts[(movie_counts > 30)].index\n",
    "rating_df = rating_df.loc[rating_df['movieId'].isin(popular_movies)]\n",
    "user_counts = rating_df['userId'].value_counts()\n",
    "popular_users = user_counts[(user_counts > 30)].index\n",
    "rating_df = rating_df.loc[rating_df['userId'].isin(popular_users)]\n",
    "\n",
    "movie_df = movie_df.loc[movie_df['movieId'].isin(rating_df['movieId'].unique())]\n",
    "movie_id_map = {v:k for k, v in enumerate(rating_df['movieId'].unique())}\n",
    "movie_df['movieId'] = movie_df['movieId'].map(movie_id_map).astype(int)\n",
    "rating_df['movieId'] = rating_df['movieId'].map(movie_id_map).astype(int)\n",
    "user_id_map = {v:k for k, v in enumerate(rating_df['userId'].unique())}\n",
    "rating_df['userId'] = rating_df['userId'].map(user_id_map).astype(int)\n",
    "rating_df = rating_df.reset_index(drop=True)\n",
    "movie_df = movie_df.reset_index(drop=True)\n",
    "mismatch = set(movie_df[\"movieId\"]).difference(rating_df[\"movieId\"])\n",
    "movie_df = movie_df.drop(mismatch)\n",
    "num_users = rating_df['userId'].nunique()\n",
    "num_movies = rating_df['movieId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51357, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.468941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.468941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.468941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.468941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.468941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>0.034820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>0.717010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>-2.445873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>-0.151232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.779027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>773 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         year\n",
       "0    0.468941\n",
       "1    0.468941\n",
       "2    0.468941\n",
       "3    0.468941\n",
       "4    0.468941\n",
       "..        ...\n",
       "768  0.034820\n",
       "769  0.717010\n",
       "770 -2.445873\n",
       "771 -0.151232\n",
       "772  0.779027\n",
       "\n",
       "[773 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = movie_df['title'].str[-5:-1].astype(float)\n",
    "# movie_features = movie_df[['title']].apply(lambda x : x.str[-5:-1].astype(float))\n",
    "year.name = 'year'\n",
    "movie_features = pd.concat([year], axis=1)\n",
    "movie_features = (movie_features - movie_features.mean(0))/movie_features.std(0)\n",
    "movie_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows=np.random.choice(rating_df.shape[0], int(0.8*rating_df.shape[0]), replace=False)\n",
    "ratings_train = rating_df.loc[train_rows]\n",
    "test_rows = set(range(rating_df.shape[0])).difference(set(train_rows))\n",
    "ratings_test = rating_df.loc[test_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minrating, maxrating = rating_df['rating'].describe().loc[['min', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((2, 3))\n",
    "b = np.random.random((2, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = np.random.random((3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.98676371, 1.83811371])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(a.dot(tr) * b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.T.dot(b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecEngine:\n",
    "    def __init__(self, ratings_train, ratings_test, num_users, num_movies, minrating, maxrating, emb_size=8,\n",
    "                 early_stopping = False, chk_freq = 10, movie_features = None, user_features = None, *args, **kwargs):\n",
    "        \n",
    "        if movie_features is not None:\n",
    "            num_movie_features = movie_features.shape[1]\n",
    "        else:\n",
    "            num_movie_features = 0\n",
    "        if user_features is not None:\n",
    "            num_user_features = user_features.shape[1]\n",
    "        else:\n",
    "            num_user_features = 0\n",
    "            \n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        if num_user_features == 0:\n",
    "            self.user_vec = tfvar(\"uservec\", shape=(num_users, emb_size + num_movie_features), dtype=tf.float32)\n",
    "        if num_movie_features == 0:\n",
    "            self.movie_vec = tfvar(\"movievec\", shape=(num_movies, emb_size + num_user_features), dtype=tf.float32)\n",
    "        if num_user_features > 0:\n",
    "            self.user_data_features = tf.constant(user_features, dtype = tf.float32)\n",
    "            self.user_vec = tf.concat((self.user_vec, self.user_data_features), axis=1)\n",
    "        \n",
    "        if num_movie_features > 0:\n",
    "            self.movie_data_features = tf.constant(movie_features, dtype = tf.float32)\n",
    "            self.movie_vec = tf.concat((self.movie_data_features, self.movie_vec), axis=1)\n",
    "            \n",
    "        \n",
    "        self.user_bias_vec = tfvar(\"userbiasvec\", shape=(num_users), dtype=tf.float32)\n",
    "        self.movie_bias_vec = tfvar(\"moviebiasvec\", shape=(num_movies), dtype=tf.float32)\n",
    "        self.ratings_train = ratings_train\n",
    "        self.ratings_test = ratings_test\n",
    "\n",
    "        self.user_ph = tfph(tf.int32, shape=(None))\n",
    "        self.movie_ph = tfph(tf.int32, shape=(None))\n",
    "        self.rating_ph = tfph(tf.float32, shape=(None))\n",
    "        \n",
    "        self.losses = []\n",
    "        self.chk_freq = chk_freq\n",
    "        self.val_losses = []\n",
    "        self.early_stopping = early_stopping\n",
    "        if self.early_stopping and chk_frq == 0:\n",
    "            raise ValueError('need a check freq if using early stopping')\n",
    "        self.n_trn = ratings_train.shape[0]\n",
    "        \n",
    "    def sample_at(self, rows):\n",
    "\n",
    "        samples = self.ratings_train.iloc[rows]\n",
    "        fd = {self.movie_ph: samples['movieId'], self.user_ph: samples['userId'], self.rating_ph: samples['rating']}\n",
    "        return fd\n",
    "    def get_fd_train(self):\n",
    "        fd = {self.movie_ph: self.ratings_train['movieId'], \n",
    "             self.user_ph: self.ratings_train['userId'], \n",
    "             self.rating_ph: self.ratings_train['rating']}\n",
    "        return fd\n",
    "    def get_fd_test(self):\n",
    "        fd =  {self.movie_ph: self.ratings_test['movieId'], \n",
    "                self.user_ph: self.ratings_test['userId'], \n",
    "                self.rating_ph: self.ratings_test['rating']}\n",
    "        return fd\n",
    "    def train(self, epochs = 100, minibatch = True, batch_size = 64):\n",
    "        for ep in tqdm(range(epochs)):\n",
    "            if minibatch:\n",
    "                data_order = np.arange(self.n_trn)\n",
    "                np.random.shuffle(data_order)\n",
    "                num_batches = self.n_trn // batch_size\n",
    "                loss_avg = 0\n",
    "                for batch_idx in range(num_batches):\n",
    "                    if batch_idx != num_batches - 1:\n",
    "                        rows = data_order[batch_idx*batch_size: (batch_idx+1) * batch_size]\n",
    "                    else:\n",
    "                        rows = data_order[batch_idx*batch_size:]\n",
    "                    fd = self.sample_at(rows)\n",
    "                    current_loss, _ = self.sess.run([self.loss, self.opt], fd)\n",
    "                    loss_avg += current_loss * len(rows) / self.n_trn\n",
    "                self.losses.append(loss_avg)\n",
    "\n",
    "            else:\n",
    "                fd = self.get_fd_train()\n",
    "                current_loss, _ = self.sess.run([self.loss, self.opt], fd)\n",
    "                self.losses.append(current_loss)\n",
    "\n",
    "            if self.early_stopping:\n",
    "                if ep % self.chk_freq == 0:\n",
    "                    last_chkpnt = f'rec_tst_{ep}'\n",
    "                    self.saver.save(self.sess, last_chkpnt)\n",
    "            fd_test = self.get_fd_test()\n",
    "            val_loss = self.sess.run(self.loss,fd_test)\n",
    "\n",
    "            self.val_losses.append(val_loss)\n",
    "            if self.early_stopping:\n",
    "                if all([los > val_losses[ep - (ep % 10)] for los in self.val_losses[-3:]]):\n",
    "                    self.saver.restore(self.sess, last_chkpnt)\n",
    "                    fd = self.get_fd_test()\n",
    "                    restored_loss = self.sess.run(self.loss, fd)\n",
    "                    self.val_losses.append(restored_loss)\n",
    "                    break\n",
    "\n",
    "    def post_setup(self):\n",
    "        self.opt_fcn = tf.compat.v1.train.AdamOptimizer()\n",
    "        self.opt = self.opt_fcn.minimize(self.loss)\n",
    "        self.sess = tf.compat.v1.Session()\n",
    "        self.sess.run(tf.compat.v1.global_variables_initializer())\n",
    "        self.saver = tf.compat.v1.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(RecEngine):\n",
    "    def __init__(self, minrating, maxrating, *args, **kwargs):\n",
    "        super().__init__(minrating=minrating, maxrating=maxrating, *args, **kwargs)\n",
    "\n",
    "        # batch size, emb_size\n",
    "        self.user_emb = tf.gather(self.user_vec, self.user_ph)\n",
    "        self.movie_emb = tf.gather(self.movie_vec, self.movie_ph)\n",
    "\n",
    "        # batch size\n",
    "        self.user_bias_emb = tf.gather(self.user_bias_vec, self.user_ph)\n",
    "        self.movie_bias_emb = tf.gather(self.movie_bias_vec, self.movie_ph)\n",
    "\n",
    "        self.score_raw = (\n",
    "            tf.reduce_sum(self.user_emb * self.movie_emb, axis=1) + self.user_bias_emb + self.movie_bias_emb\n",
    "        )\n",
    "        self.score = tf.sigmoid(self.score_raw) * (maxrating - minrating) + minrating\n",
    "\n",
    "        self.reg = tf.reduce_mean(tf.square(self.user_emb)) + tf.reduce_mean(tf.square(self.movie_emb))\n",
    "\n",
    "        self.mse = tf.reduce_mean(tf.square(self.score - self.rating_ph))\n",
    "        self.loss = self.mse + self.reg\n",
    "        self.post_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecEngine_with_features(RecEngine):\n",
    "    def __init__(self, minrating, maxrating, *args, **kwargs):\n",
    "        super().__init__(minrating=minrating, maxrating=maxrating, *args, **kwargs)\n",
    "\n",
    "        # batch size, emb_size\n",
    "        self.user_emb = tf.gather(self.user_vec, self.user_ph)\n",
    "        self.movie_emb = tf.gather(self.movie_vec, self.movie_ph)\n",
    "        if self.user_data_features is not None:\n",
    "            self.user_emb = tf.concat((self.user_emb, self.user_data_features), axis=1)\n",
    "        if self.movie_emb is not None:\n",
    "            self.movie_emb = tf.concat((self.movie_data_features, self.movie_emb), axis=1)\n",
    "\n",
    "        # batch size\n",
    "        self.user_bias_emb = tf.gather(self.user_bias_vec, self.user_ph)\n",
    "        self.movie_bias_emb = tf.gather(self.movie_bias_vec, self.movie_ph)\n",
    "\n",
    "        self.score_raw = (\n",
    "            tf.reduce_sum(self.user_emb * self.movie_emb, axis=1) + self.user_bias_emb + self.movie_bias_emb\n",
    "        )\n",
    "        self.score = tf.sigmoid(self.score_raw) * (maxrating - minrating) + minrating\n",
    "\n",
    "        self.reg = tf.reduce_mean(tf.square(self.user_emb)) + tf.reduce_mean(tf.square(self.movie_emb))\n",
    "\n",
    "        self.mse = tf.reduce_mean(tf.square(self.score - self.rating_ph))\n",
    "        self.loss = self.mse + self.reg\n",
    "        self.post_setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MF' object has no attribute 'movie_vec'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e1a6e765b032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_eager_execution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m mf_mdl = MF(ratings_train=ratings_train, ratings_test=ratings_test, num_users=num_users, num_movies=num_movies,\n\u001b[1;32m----> 5\u001b[1;33m             minrating=minrating, maxrating=maxrating, emb_size=64, movie_features = movie_features, user_features = None)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-c991ea4698d2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, minrating, maxrating, *args, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mMF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRecEngine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminrating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxrating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxrating\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m# batch size, emb_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-0165906d2260>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, ratings_train, ratings_test, num_users, num_movies, minrating, maxrating, emb_size, early_stopping, chk_freq, movie_features, user_features, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_movie_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovie_data_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmovie_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovie_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovie_data_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovie_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnum_user_feautres\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnum_movie_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_data_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MF' object has no attribute 'movie_vec'"
     ]
    }
   ],
   "source": [
    "tfph = tf.compat.v1.placeholder\n",
    "tfvar = tf.compat.v1.get_variable\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "mf_mdl = MF(ratings_train=ratings_train, ratings_test=ratings_test, num_users=num_users, num_movies=num_movies,\n",
    "            minrating=minrating, maxrating=maxrating, emb_size=64, movie_features = movie_features, user_features = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature_with_mdl = RecEngine_with_features(\n",
    "#     ratings_train=ratings_train, ratings_test=ratings_test, num_users=num_users, num_movies=num_movies,\n",
    "#             minrating=minrating, maxrating=maxrating, emb_size=64, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset: 22M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mf_mdl.train(epochs = 30, batch_size = {False:2**21, True:64}[dbg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(mf_mdl.val_losses[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mf_mdl = MF(ratings_train=ratings_train, ratings_test=ratings_test, num_users=num_users, num_movies=num_movies,\n",
    "            minrating=minrating, maxrating=maxrating, emb_size=64, movie_features = movie_features, user_features = None)\n",
    "mf_mdl.train(epochs = 30, batch_size = {False:2**21, True:64}[dbg])\n",
    "plt.plot(mf_mdl.val_losses[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mf_mdl = MF(ratings_train=ratings_train, ratings_test=ratings_test, num_users=num_users, num_movies=num_movies,\n",
    "            minrating=minrating, maxrating=maxrating, emb_size=64, movie_features = movie_features, user_features = None)\n",
    "mf_mdl.train(epochs = 30, batch_size = {False:2**21, True:64}[dbg])\n",
    "plt.plot(mf_mdl.val_losses[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mf_mdl = MF(ratings_train=ratings_train, ratings_test=ratings_test, num_users=num_users, num_movies=num_movies,\n",
    "            minrating=minrating, maxrating=maxrating, emb_size=64, movie_features = None, user_features = None)\n",
    "mf_mdl.train(epochs = 30, batch_size = {False:2**21, True:64}[dbg])\n",
    "plt.plot(mf_mdl.val_losses[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mf_mdl = MF(ratings_train=ratings_train, ratings_test=ratings_test, num_users=num_users, num_movies=num_movies,\n",
    "            minrating=minrating, maxrating=maxrating, emb_size=64, movie_features = None, user_features = None)\n",
    "mf_mdl.train(epochs = 30, batch_size = {False:2**21, True:64}[dbg])\n",
    "plt.plot(mf_mdl.val_losses[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Joel_2022_7_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
